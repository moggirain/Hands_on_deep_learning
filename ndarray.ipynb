{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76918dda",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 数据操作\n",
    ":label:`sec_ndarray`\n",
    "\n",
    "为了能够完成各种数据操作，我们需要某种方法来存储和操作数据。\n",
    "通常，我们需要做两件重要的事：（1）获取数据；（2）将数据读入计算机后对其进行处理。\n",
    "如果没有某种方法来存储数据，那么获取数据是没有意义的。\n",
    "\n",
    "首先，我们介绍$n$维数组，也称为*张量*（tensor）。\n",
    "使用过Python中NumPy计算包的读者会对本部分很熟悉。\n",
    "无论使用哪个深度学习框架，它的*张量类*（在MXNet中为`ndarray`，\n",
    "在PyTorch和TensorFlow中为`Tensor`）都与Numpy的`ndarray`类似。\n",
    "但深度学习框架又比Numpy的`ndarray`多一些重要功能：\n",
    "首先，GPU很好地支持加速计算，而NumPy仅支持CPU计算；\n",
    "其次，张量类支持自动微分。\n",
    "这些功能使得张量类更适合深度学习。\n",
    "如果没有特殊说明，本书中所说的张量均指的是张量类的实例。\n",
    "\n",
    "## 入门\n",
    "\n",
    "本节的目标是帮助读者了解并运行一些在阅读本书的过程中会用到的基本数值计算工具。\n",
    "如果你很难理解一些数学概念或库函数，请不要担心。\n",
    "后面的章节将通过一些实际的例子来回顾这些内容。\n",
    "如果你已经具有相关经验，想要深入学习数学内容，可以跳过本节。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a77426",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "(**首先，我们导入`torch`。请注意，虽然它被称为PyTorch，但是代码中使用`torch`而不是`pytorch`。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05fbe34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.132955Z",
     "start_time": "2022-09-12T15:39:20.038036Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:13.962912Z",
     "iopub.status.busy": "2022-07-31T02:18:13.962445Z",
     "iopub.status.idle": "2022-07-31T02:18:14.683806Z",
     "shell.execute_reply": "2022-07-31T02:18:14.683047Z"
    },
    "origin_pos": 5,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eddb70",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "[**张量表示由一个数值组成的数组，这个数组可能有多个维度**]。\n",
    "具有一个轴的张量对应数学上的*向量*（vector）；\n",
    "具有两个轴的张量对应数学上的*矩阵*（matrix）；\n",
    "具有两个轴以上的张量没有特殊的数学名称。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1aab1",
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "首先，我们可以使用 `arange` 创建一个行向量 `x`。这个行向量包含以0开始的前12个整数，它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的 *元素*（element）。例如，张量 `x` 中有 12 个元素。除非额外指定，新的张量将存储在内存中，并采用基于CPU的计算。\n",
    "\n",
    "**arange is for 1D tensor** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0772c3dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.152929Z",
     "start_time": "2022-09-12T15:39:21.137571Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.687487Z",
     "iopub.status.busy": "2022-07-31T02:18:14.687092Z",
     "iopub.status.idle": "2022-07-31T02:18:14.698472Z",
     "shell.execute_reply": "2022-07-31T02:18:14.697874Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f26d3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.168678Z",
     "start_time": "2022-09-12T15:39:21.158506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  7,  9, 11])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(start, end, step)\n",
    "y = torch.arange(5,12,2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc166f",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "[**可以通过张量的`shape`属性来访问张量（沿每个轴的长度）的*形状***]\n",
    "(~~和张量中元素的总数~~)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458be81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T05:33:03.257403Z",
     "start_time": "2022-09-12T05:33:03.241215Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82eeca50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.185046Z",
     "start_time": "2022-09-12T15:39:21.176006Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.703433Z",
     "iopub.status.busy": "2022-07-31T02:18:14.703051Z",
     "iopub.status.idle": "2022-07-31T02:18:14.708075Z",
     "shell.execute_reply": "2022-07-31T02:18:14.707270Z"
    },
    "origin_pos": 15,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdea867",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。\n",
    "因为这里在处理的是一个向量，所以它的`shape`与它的`size`相同。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e043a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.218369Z",
     "start_time": "2022-09-12T15:39:21.189256Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.711683Z",
     "iopub.status.busy": "2022-07-31T02:18:14.710908Z",
     "iopub.status.idle": "2022-07-31T02:18:14.716724Z",
     "shell.execute_reply": "2022-07-31T02:18:14.715786Z"
    },
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5694d20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.316483Z",
     "start_time": "2022-09-12T15:39:21.266043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10259c",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "[**要想改变一个张量的形状而不改变元素数量和元素值，可以调用`reshape`函数。**]\n",
    "例如，可以把张量`x`从形状为（12,）的行向量转换为形状为（3,4）的矩阵。\n",
    "这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。\n",
    "要重点说明一下，虽然张量的形状发生了改变，但其元素值并没有变。\n",
    "注意，通过改变张量的形状，张量的大小不会改变。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0f1946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.340831Z",
     "start_time": "2022-09-12T15:39:21.324040Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.719843Z",
     "iopub.status.busy": "2022-07-31T02:18:14.719478Z",
     "iopub.status.idle": "2022-07-31T02:18:14.726230Z",
     "shell.execute_reply": "2022-07-31T02:18:14.725362Z"
    },
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e07cbbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.365971Z",
     "start_time": "2022-09-12T15:39:21.349071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5],\n",
      "        [ 7],\n",
      "        [ 9],\n",
      "        [11]])\n",
      "tensor([[ 5,  7,  9, 11]])\n",
      "tensor([[ 5,  7],\n",
      "        [ 9, 11]])\n"
     ]
    }
   ],
   "source": [
    "Y = y.reshape(4,-1)\n",
    "print(Y)\n",
    "Y2 = y.reshape(-1,4)\n",
    "print(Y2)\n",
    "Y3 = y.reshape(2,2)\n",
    "print(Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea0669",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "我们不需要通过手动指定每个维度来改变形状。\n",
    "也就是说，如果我们的目标形状是（高度,宽度），\n",
    "那么在知道宽度后，高度会被自动计算得出，不必我们自己做除法。\n",
    "在上面的例子中，为了获得一个3行的矩阵，我们手动指定了它有3行和4列。\n",
    "幸运的是，我们可以通过`-1`来调用此自动计算出维度的功能。\n",
    "即我们可以用`x.reshape(-1,4)`或`x.reshape(3,-1)`来取代`x.reshape(3,4)`。\n",
    "\n",
    "有时，我们希望[**使用全0、全1、其他常量，或者从特定分布中随机采样的数字**]来初始化矩阵。\n",
    "我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。代码如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81129c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.398171Z",
     "start_time": "2022-09-12T15:39:21.379496Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.730172Z",
     "iopub.status.busy": "2022-07-31T02:18:14.729443Z",
     "iopub.status.idle": "2022-07-31T02:18:14.736998Z",
     "shell.execute_reply": "2022-07-31T02:18:14.736078Z"
    },
    "origin_pos": 25,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efa60f",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "同样，我们可以创建一个形状为`(2,3,4)`的张量，其中所有元素都设置为1。代码如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67243de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.479481Z",
     "start_time": "2022-09-12T15:39:21.461210Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.741124Z",
     "iopub.status.busy": "2022-07-31T02:18:14.740532Z",
     "iopub.status.idle": "2022-07-31T02:18:14.748021Z",
     "shell.execute_reply": "2022-07-31T02:18:14.747164Z"
    },
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af1bf6",
   "metadata": {
    "origin_pos": 31
   },
   "source": [
    "有时我们想通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。\n",
    "例如，当我们构造数组来作为神经网络中的参数时，我们通常会随机初始化参数的值。\n",
    "以下代码创建一个形状为（3,4）的张量。\n",
    "其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5227275f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.507159Z",
     "start_time": "2022-09-12T15:39:21.489437Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.751936Z",
     "iopub.status.busy": "2022-07-31T02:18:14.751150Z",
     "iopub.status.idle": "2022-07-31T02:18:14.758391Z",
     "shell.execute_reply": "2022-07-31T02:18:14.757602Z"
    },
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7751, -0.2731,  0.2006,  0.5868],\n",
       "        [-0.8926,  0.2459, -0.9035,  0.7045],\n",
       "        [-1.5676, -0.2371, -0.1373,  0.7518]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3889d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.532310Z",
     "start_time": "2022-09-12T15:39:21.516695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6661,  0.6195,  0.1154, -1.0498,  0.7594, -0.9490],\n",
       "         [-0.8306, -1.2208, -0.3569, -0.0679,  0.4387,  1.0692],\n",
       "         [ 0.0600,  0.9776, -0.2353,  0.1994,  0.7199,  0.8597],\n",
       "         [-0.7905,  1.0726,  0.6348,  0.0969,  1.3439,  0.9540],\n",
       "         [-0.1243, -0.1144,  0.4690,  2.6312,  0.4570, -0.2480]],\n",
       "\n",
       "        [[-0.2315,  0.7776, -0.5576, -0.6218,  1.7580,  1.0430],\n",
       "         [-0.3582, -1.2108,  0.1680,  1.0558,  0.7896,  0.5503],\n",
       "         [-1.7033, -0.2052, -0.0048,  1.3776, -0.9539, -1.4807],\n",
       "         [-0.8634, -0.5304,  0.5401,  0.1719, -0.6049, -0.7269],\n",
       "         [-0.0659, -0.1633,  2.1903,  0.9309,  0.0924,  1.4950]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4173078",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "我们还可以[**通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值**]。\n",
    "在这里，最外层的列表对应于轴0，内层的列表对应于轴1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f989db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.544217Z",
     "start_time": "2022-09-12T15:39:21.536917Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.762256Z",
     "iopub.status.busy": "2022-07-31T02:18:14.761498Z",
     "iopub.status.idle": "2022-07-31T02:18:14.769515Z",
     "shell.execute_reply": "2022-07-31T02:18:14.768586Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "z = torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35936c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.565998Z",
     "start_time": "2022-09-12T15:39:21.554019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3],\n",
       "        [1, 2, 3, 4],\n",
       "        [4, 3, 2, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a250f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.585106Z",
     "start_time": "2022-09-12T15:39:21.573117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d14e105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.599987Z",
     "start_time": "2022-09-12T15:39:21.590845Z"
    }
   },
   "outputs": [],
   "source": [
    "zz = torch.tensor([[[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa61a82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.613643Z",
     "start_time": "2022-09-12T15:39:21.605448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a35c7484",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.627421Z",
     "start_time": "2022-09-12T15:39:21.618943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4, 3, 1, 2, 3, 4, 4, 3, 2, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.reshape(-1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a58e5f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.641786Z",
     "start_time": "2022-09-12T15:39:21.633863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4],\n",
       "        [3, 1, 2],\n",
       "        [3, 4, 4],\n",
       "        [3, 2, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.view(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21742304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.665739Z",
     "start_time": "2022-09-12T15:39:21.651191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4],\n",
       "        [1, 2, 3],\n",
       "        [4, 3, 2],\n",
       "        [3, 4, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.transpose(-2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4224ac35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.689127Z",
     "start_time": "2022-09-12T15:39:21.673726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3740, 0.6142, 0.1792],\n",
      "        [0.0598, 0.3976, 0.3862],\n",
      "        [0.7619, 0.1230, 0.4428]])\n",
      "tensor([[0.3740, 0.0598, 0.7619],\n",
      "        [0.6142, 0.3976, 0.1230],\n",
      "        [0.1792, 0.3862, 0.4428]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3,3)\n",
    "print(a)\n",
    "b = a.permute(1,0) # Returns a view of the original tensor input with its dimensions permuted.\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a11a6",
   "metadata": {
    "origin_pos": 39
   },
   "source": [
    "## 运算符\n",
    "\n",
    "我们的兴趣不仅限于读取数据和写入数据。\n",
    "我们想在这些数据上执行数学运算，其中最简单且最有用的操作是*按元素*（elementwise）运算。\n",
    "它们将标准标量运算符应用于数组的每个元素。\n",
    "对于将两个数组作为输入的函数，按元素运算将二元运算符应用于两个数组中的每对位置对应的元素。\n",
    "我们可以基于任何从标量到标量的函数来创建按元素函数。\n",
    "\n",
    "在数学表示法中，我们将通过符号$f: \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
    "来表示*一元*标量运算符（只接收一个输入）。\n",
    "这意味着该函数从任何实数（$\\mathbb{R}$）映射到另一个实数。\n",
    "同样，我们通过符号$f: \\mathbb{R}, \\mathbb{R} \\rightarrow \\mathbb{R}$\n",
    "表示*二元*标量运算符，这意味着该函数接收两个输入，并产生一个输出。\n",
    "给定同一形状的任意两个向量$\\mathbf{u}$和$\\mathbf{v}$和二元运算符$f$，\n",
    "我们可以得到向量$\\mathbf{c} = F(\\mathbf{u},\\mathbf{v})$。\n",
    "具体计算方法是$c_i \\gets f(u_i, v_i)$，\n",
    "其中$c_i$、$u_i$和$v_i$分别是向量$\\mathbf{c}$、$\\mathbf{u}$和$\\mathbf{v}$中的元素。\n",
    "在这里，我们通过将标量函数升级为按元素向量运算来生成向量值\n",
    "$F: \\mathbb{R}^d, \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$。\n",
    "\n",
    "对于任意具有相同形状的张量，\n",
    "[**常见的标准算术运算符（`+`、`-`、`*`、`/`和`**`）都可以被升级为按元素运算**]。\n",
    "我们可以在同一形状的任意两个张量上调用按元素操作。\n",
    "在下面的例子中，我们使用逗号来表示一个具有5个元素的元组，其中每个元素都是按元素操作的结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c350a6ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.709635Z",
     "start_time": "2022-09-12T15:39:21.693634Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.773563Z",
     "iopub.status.busy": "2022-07-31T02:18:14.772808Z",
     "iopub.status.idle": "2022-07-31T02:18:14.784552Z",
     "shell.execute_reply": "2022-07-31T02:18:14.783458Z"
    },
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69252b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.727765Z",
     "start_time": "2022-09-12T15:39:21.715265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3,  4,  6, 10]),\n",
       " tensor([-1,  0,  2,  6]),\n",
       " tensor([ 2,  4,  8, 16]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1,  4, 16, 64]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not put 1.0 as a float, the differenc will be do int operation \n",
    "x = torch.tensor([1, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068b5b8",
   "metadata": {
    "origin_pos": 43
   },
   "source": [
    "(**“按元素”方式可以应用更多的计算**)，包括像求幂这样的一元运算符。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4550d12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.745365Z",
     "start_time": "2022-09-12T15:39:21.733265Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.788732Z",
     "iopub.status.busy": "2022-07-31T02:18:14.788133Z",
     "iopub.status.idle": "2022-07-31T02:18:14.796104Z",
     "shell.execute_reply": "2022-07-31T02:18:14.794959Z"
    },
    "origin_pos": 45,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x) # e**x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cc670",
   "metadata": {
    "origin_pos": 47
   },
   "source": [
    "除了按元素计算外，我们还可以执行线性代数运算，包括向量点积和矩阵乘法。\n",
    "我们将在 :numref:`sec_linear-algebra`中解释线性代数的重点内容。\n",
    "\n",
    "[**我们也可以把多个张量*连结*（concatenate）在一起**]，\n",
    "把它们端对端地叠起来形成一个更大的张量。\n",
    "我们只需要提供张量列表，并给出沿哪个轴连结。\n",
    "下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素）\n",
    "和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。\n",
    "我们可以看到，第一个输出张量的轴-0长度（$6$）是两个输入张量轴-0长度的总和（$3 + 3$）；\n",
    "第二个输出张量的轴-1长度（$8$）是两个输入张量轴-1长度的总和（$4 + 4$）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60fce770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.770024Z",
     "start_time": "2022-09-12T15:39:21.753676Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.799639Z",
     "iopub.status.busy": "2022-07-31T02:18:14.799002Z",
     "iopub.status.idle": "2022-07-31T02:18:14.810588Z",
     "shell.execute_reply": "2022-07-31T02:18:14.809683Z"
    },
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)# dim = 0 y 方向拼接 dim = 1 x方向拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ee45dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.804518Z",
     "start_time": "2022-09-12T15:39:21.774641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 2.,  1.,  4.,  3.],\n",
       "         [ 1.,  2.,  3.,  4.],\n",
       "         [ 4.,  3.,  2.,  1.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "torch.cat((X, Y), dim=-1), torch.cat((X, Y), dim=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a17611",
   "metadata": {
    "origin_pos": 51
   },
   "source": [
    "有时，我们想[**通过*逻辑运算符*构建二元张量**]。\n",
    "以`X == Y`为例：\n",
    "对于每个位置，如果`X`和`Y`在该位置相等，则新张量中相应项的值为1。\n",
    "这意味着逻辑语句`X == Y`在该位置处为真，否则该位置为0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16aff702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.825679Z",
     "start_time": "2022-09-12T15:39:21.810850Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.813799Z",
     "iopub.status.busy": "2022-07-31T02:18:14.813591Z",
     "iopub.status.idle": "2022-07-31T02:18:14.818445Z",
     "shell.execute_reply": "2022-07-31T02:18:14.817794Z"
    },
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c8e62eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.879453Z",
     "start_time": "2022-09-12T15:39:21.865837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.equal(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727a92b",
   "metadata": {
    "origin_pos": 53
   },
   "source": [
    "[**对张量中的所有元素进行求和，会产生一个单元素张量。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2929b13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.902478Z",
     "start_time": "2022-09-12T15:39:21.888275Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.821528Z",
     "iopub.status.busy": "2022-07-31T02:18:14.821076Z",
     "iopub.status.idle": "2022-07-31T02:18:14.825960Z",
     "shell.execute_reply": "2022-07-31T02:18:14.825290Z"
    },
    "origin_pos": 54,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(66.), tensor(30.))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(), Y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d37b7e",
   "metadata": {
    "origin_pos": 56
   },
   "source": [
    "## 广播机制\n",
    ":label:`subsec_broadcasting`\n",
    "\n",
    "在上面的部分中，我们看到了如何在相同形状的两个张量上执行按元素操作。\n",
    "在某些情况下，[**即使形状不同，我们仍然可以通过调用\n",
    "*广播机制*（broadcasting mechanism）来执行按元素操作**]。\n",
    "这种机制的工作方式如下：首先，通过适当复制元素来扩展一个或两个数组，\n",
    "以便在转换之后，两个张量具有相同的形状。\n",
    "其次，对生成的数组执行按元素操作。\n",
    "\n",
    "在大多数情况下，我们将沿着数组中长度为1的轴进行广播，如下例子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e6a50db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.928829Z",
     "start_time": "2022-09-12T15:39:21.917682Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.828845Z",
     "iopub.status.busy": "2022-07-31T02:18:14.828629Z",
     "iopub.status.idle": "2022-07-31T02:18:14.835266Z",
     "shell.execute_reply": "2022-07-31T02:18:14.834338Z"
    },
    "origin_pos": 58,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af988b",
   "metadata": {
    "origin_pos": 60
   },
   "source": [
    "由于`a`和`b`分别是$3\\times1$和$1\\times2$矩阵，如果让它们相加，它们的形状不匹配。\n",
    "我们将两个矩阵*广播*为一个更大的$3\\times2$矩阵，如下所示：矩阵`a`将复制列，\n",
    "矩阵`b`将复制行，然后再按元素相加。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f97353c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.948597Z",
     "start_time": "2022-09-12T15:39:21.939137Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.839218Z",
     "iopub.status.busy": "2022-07-31T02:18:14.838457Z",
     "iopub.status.idle": "2022-07-31T02:18:14.845915Z",
     "shell.execute_reply": "2022-07-31T02:18:14.844907Z"
    },
    "origin_pos": 61,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b028e7d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:21.961127Z",
     "start_time": "2022-09-12T15:39:21.955086Z"
    }
   },
   "outputs": [],
   "source": [
    "c = torch.randn(3,4).reshape((4, 3))\n",
    "d = torch.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86bfc820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.736774Z",
     "start_time": "2022-09-12T15:39:21.968884Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "c + d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d822c22",
   "metadata": {
    "origin_pos": 62
   },
   "source": [
    "## 索引和切片\n",
    "\n",
    "就像在任何其他Python数组中一样，张量中的元素可以通过索引访问。\n",
    "与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1；\n",
    "可以指定范围以包含第一个元素和最后一个之前的元素。\n",
    "\n",
    "如下所示，我们[**可以用`[-1]`选择最后一个元素，可以用`[1:3]`选择第二个和第三个元素**]：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82c22135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:40:07.667793Z",
     "start_time": "2022-09-12T15:40:07.658810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e7b1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:40:46.628569Z",
     "start_time": "2022-09-12T15:40:46.621441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3.],\n",
       "        [4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:-1] # all to the last row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9194e833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:41:19.661510Z",
     "start_time": "2022-09-12T15:41:19.653051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1:]# last row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ad0df53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:42:12.881779Z",
     "start_time": "2022-09-12T15:42:12.872833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  7., 11.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,-1] # last column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fbbcf30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:40:00.439913Z",
     "start_time": "2022-09-12T15:40:00.429596Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.849759Z",
     "iopub.status.busy": "2022-07-31T02:18:14.849160Z",
     "iopub.status.idle": "2022-07-31T02:18:14.856410Z",
     "shell.execute_reply": "2022-07-31T02:18:14.855540Z"
    },
    "origin_pos": 63,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]),\n",
       " tensor([[ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d06f900c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:42:44.323671Z",
     "start_time": "2022-09-12T15:42:44.315468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[::3, ::2]# all column,element in every 3 step starting at 0, all row, element in every 2 step starting at 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8c91e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:44:10.978559Z",
     "start_time": "2022-09-12T15:44:10.971080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.],\n",
       "        [ 8., 10.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[::2, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0deb4",
   "metadata": {
    "origin_pos": 64,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**除读取外，我们还可以通过指定索引来将元素写入矩阵。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a620d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.808587Z",
     "start_time": "2022-09-12T15:39:22.808548Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.860493Z",
     "iopub.status.busy": "2022-07-31T02:18:14.859755Z",
     "iopub.status.idle": "2022-07-31T02:18:14.866298Z",
     "shell.execute_reply": "2022-07-31T02:18:14.865434Z"
    },
    "origin_pos": 66,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "X[1, 2] = 9\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400e726",
   "metadata": {
    "origin_pos": 68
   },
   "source": [
    "如果我们想[**为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。**]\n",
    "例如，`[0:2, :]`访问第1行和第2行，其中“:”代表沿轴1（列）的所有元素。\n",
    "虽然我们讨论的是矩阵的索引，但这也适用于向量和超过2个维度的张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd3458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.811946Z",
     "start_time": "2022-09-12T15:39:22.811914Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.869487Z",
     "iopub.status.busy": "2022-07-31T02:18:14.868918Z",
     "iopub.status.idle": "2022-07-31T02:18:14.875244Z",
     "shell.execute_reply": "2022-07-31T02:18:14.874325Z"
    },
    "origin_pos": 69,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "X[0:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769a410",
   "metadata": {
    "origin_pos": 71
   },
   "source": [
    "## 节省内存\n",
    "\n",
    "[**运行一些操作可能会导致为新结果分配内存**]。\n",
    "例如，如果我们用`Y = X + Y`，我们将取消引用`Y`指向的张量，而是指向新分配的内存处的张量。\n",
    "\n",
    "在下面的例子中，我们用Python的`id()`函数演示了这一点，\n",
    "它给我们提供了内存中引用对象的确切地址。\n",
    "运行`Y = Y + X`后，我们会发现`id(Y)`指向另一个位置。\n",
    "这是因为Python首先计算`Y + X`，为结果分配新的内存，然后使`Y`指向内存中的这个新位置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cfd4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.821399Z",
     "start_time": "2022-09-12T15:39:22.821366Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.878510Z",
     "iopub.status.busy": "2022-07-31T02:18:14.878253Z",
     "iopub.status.idle": "2022-07-31T02:18:14.883781Z",
     "shell.execute_reply": "2022-07-31T02:18:14.882922Z"
    },
    "origin_pos": 72,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "before = id(Y)\n",
    "Y = Y + X\n",
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f292984",
   "metadata": {
    "origin_pos": 73
   },
   "source": [
    "这可能是不可取的，原因有两个：首先，我们不想总是不必要地分配内存。\n",
    "在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。\n",
    "通常情况下，我们希望原地执行这些更新。\n",
    "其次，如果我们不原地更新，其他引用仍然会指向旧的内存位置，\n",
    "这样我们的某些代码可能会无意中引用旧的参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afb52c",
   "metadata": {
    "origin_pos": 74,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "幸运的是，(**执行原地操作**)非常简单。\n",
    "我们可以使用切片表示法将操作的结果分配给先前分配的数组，例如`Y[:] = <expression>`。\n",
    "为了说明这一点，我们首先创建一个新的矩阵`Z`，其形状与另一个`Y`相同，\n",
    "使用`zeros_like`来分配一个全$0$的块。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d07ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.840248Z",
     "start_time": "2022-09-12T15:39:22.840213Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.886922Z",
     "iopub.status.busy": "2022-07-31T02:18:14.886668Z",
     "iopub.status.idle": "2022-07-31T02:18:14.892130Z",
     "shell.execute_reply": "2022-07-31T02:18:14.891483Z"
    },
    "origin_pos": 77,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "Z = torch.zeros_like(Y)\n",
    "print('id(Z):', id(Z))\n",
    "Z[:] = X + Y\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4300d",
   "metadata": {
    "origin_pos": 79,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[**如果在后续计算中没有重复使用`X`，\n",
    "我们也可以使用`X[:] = X + Y`或`X += Y`来减少操作的内存开销。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3b772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.843932Z",
     "start_time": "2022-09-12T15:39:22.843898Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.895112Z",
     "iopub.status.busy": "2022-07-31T02:18:14.894585Z",
     "iopub.status.idle": "2022-07-31T02:18:14.900298Z",
     "shell.execute_reply": "2022-07-31T02:18:14.899621Z"
    },
    "origin_pos": 81,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "before = id(X)\n",
    "X += Y\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd920d15",
   "metadata": {
    "origin_pos": 83
   },
   "source": [
    "## 转换为其他Python对象\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49606e1",
   "metadata": {
    "origin_pos": 85,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "将深度学习框架定义的张量[**转换为NumPy张量（`ndarray`）**]很容易，反之也同样容易。\n",
    "torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6ca45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.859953Z",
     "start_time": "2022-09-12T15:39:22.859927Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.903817Z",
     "iopub.status.busy": "2022-07-31T02:18:14.903370Z",
     "iopub.status.idle": "2022-07-31T02:18:14.910321Z",
     "shell.execute_reply": "2022-07-31T02:18:14.909306Z"
    },
    "origin_pos": 87,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "A = X.numpy()\n",
    "B = torch.tensor(A)\n",
    "type(A), type(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f24f4",
   "metadata": {
    "origin_pos": 89
   },
   "source": [
    "要(**将大小为1的张量转换为Python标量**)，我们可以调用`item`函数或Python的内置函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c47523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.872973Z",
     "start_time": "2022-09-12T15:39:22.872947Z"
    },
    "execution": {
     "iopub.execute_input": "2022-07-31T02:18:14.913427Z",
     "iopub.status.busy": "2022-07-31T02:18:14.912724Z",
     "iopub.status.idle": "2022-07-31T02:18:14.920422Z",
     "shell.execute_reply": "2022-07-31T02:18:14.919387Z"
    },
    "origin_pos": 91,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([3.5])\n",
    "a, a.item(), float(a), int(a) # a.item = numpy float "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1466e5",
   "metadata": {
    "origin_pos": 93
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 深度学习存储和操作数据的主要接口是张量（$n$维数组）。它提供了各种功能，包括基本数学运算、广播、索引、切片、内存节省和转换其他Python对象。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 运行本节中的代码。将本节中的条件语句`X == Y`更改为`X < Y`或`X > Y`，然后看看你可以得到什么样的张量。\n",
    "1. 用其他形状（例如三维张量）替换广播机制中按元素操作的两个张量。结果是否与预期相同？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3ea6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.876262Z",
     "start_time": "2022-09-12T15:39:22.876222Z"
    }
   },
   "outputs": [],
   "source": [
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "X = torch.rand(3,4)\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51042a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.883667Z",
     "start_time": "2022-09-12T15:39:22.883629Z"
    }
   },
   "outputs": [],
   "source": [
    "X < Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a666c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T15:39:22.887985Z",
     "start_time": "2022-09-12T15:39:22.887943Z"
    }
   },
   "outputs": [],
   "source": [
    "X > Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50522546",
   "metadata": {
    "origin_pos": 95,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1747)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
